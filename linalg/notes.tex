\documentclass[a4paper]{article}

\usepackage[margin=2.5cm]{geometry}
\usepackage[pdftex]{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[colorlinks=true,linkcolor=blue]{hyperref}
\usepackage{float}
\usepackage{mathrsfs}
%\usepackage{enumitem}
%% for identity function 1:
\usepackage{bbm}
%%For category theory diagrams:
%\usepackage{tikz-cd}
%%For code (e.g. python) in latex:
%\usepackage{listings}
%
%Usage: 
%\begin{lstlisting}[language=Python]
%\end{lstlisting}

\newcommand{\incfig}[2][1]{%
\def\svgwidth{#1\columnwidth}
\import{./figures/}{#2.pdf_tex}
}

\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem*{corollary}{Corollary}


\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{exercise}[example]{Exercise}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

% figure support
\usepackage{import}
\usepackage{xifthen}
\pdfminorversion=7
\usepackage{pdfpages}
\usepackage{transparent}

\pdfsuppresswarningpagegroup=1

\setlength\parindent{0pt}

\newcommand{\qedwhite}{\hfill \ensuremath{\Box}}

%Inequalities
\newcommand{\cycsum}{\sum_{\mathrm{cyc}}}
\newcommand{\symsum}{\sum_{\mathrm{sym}}}
\newcommand{\cycprod}{\prod_{\mathrm{cyc}}}
\newcommand{\symprod}{\prod_{\mathrm{sym}}}

%Linear Algebra

\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\ob}{ob}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\sk}{sk}
\DeclareMathOperator{\Vect}{Vect}
\DeclareMathOperator{\Set}{Set}
\DeclareMathOperator{\Group}{Group}
\DeclareMathOperator{\Ring}{Ring}
\DeclareMathOperator{\Ab}{Ab}
\DeclareMathOperator{\Top}{Top}
\DeclareMathOperator{\Htpy}{Htpy}
\DeclareMathOperator{\Cat}{Cat}
\DeclareMathOperator{\CAT}{CAT}
\DeclareMathOperator{\Cone}{Cone}


%Row operations
\newcommand{\elem}[1]{% elementary operations
\xrightarrow{\substack{#1}}%
}

\newcommand{\lelem}[1]{% elementary operations (left alignment)
\xrightarrow{\begin{subarray}{l}#1\end{subarray}}%
}

%SS
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\Var}{Var}

%NT
\DeclareMathOperator{\ord}{ord}

%Alg
\DeclareMathOperator{\Rad}{Rad}
\DeclareMathOperator{\Jac}{Jac}

\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\newcommand{\unif}{\pazocal{U}}

\begin{document}
\section{Vector spaces}


    \textbf{Problem 2.4.(8):} Let $V$ be the space of $2 \times 2$ matrices
    over $\mathbb{F}$. Find a basis
    $\left\{ A_1, A_2, A_3, A_4 \right\} $ for $V$ such that
    $A_i^2 = A_i$ for each $i$.\\
    \linebreak
    \textit{Solution:} 
    \[
    \begin{pmatrix} 
        1 & 0\\
        0 & 0
    \end{pmatrix} \quad
    \begin{pmatrix} 
        0 & 0\\
        0 & 1
    \end{pmatrix} \quad
    \begin{pmatrix} 
        0 & 1\\
        0 & 1
    \end{pmatrix} \quad
    \begin{pmatrix} 
        0 & 0\\
        1 & 1
    \end{pmatrix} 
    \] 
    

    \textbf{Problem 2.5.(6):} A littleo n linear independence and change of
    coordinates. Let $V$ be the vector space over the complex numbers of all
    functions $\mathbb{R} \to \mathbb{C}$. Let
    $f_1 = 1, f_2(x) = e^{ix}, f_3(x) = e^{-ix}$.\\
    \linebreak
    Firstly, $ f_1,f_2$
 and $f_3$ are lin. indep. since if
 \begin{align*}
     a f_1 + bf_2 + cf_3
     = a \cdot 1 + b \cdot e^{ix} + c \cdot e^{-ix} = 0
 \end{align*}
 then
 $a + i (b-c) = 0$ so $a = 0$ and $b = c$, but also
 $a + b+ c = 0$ so $b = -c$. Hence $b = 0 = c$.\\
 Now let $g_1 = 1, g_2(x) = \cos x , g_3(x) = \sin x$. Find
 an invertible $3 \times 3$ matrix $P$ such that
 \[
 g_j = \sum_{i=1}^{3} P_{ij}f_i.
 \] 
\textit{Solution:}
We have $g_1 = 1 \cdot f_1$, so
$P_{1,1}=1, P_{1,2}=P_{1,3}=0$.
Now $g_2 = \frac{1}{2} f_2 + \frac{1}{2}f_3$.\\
And $g_3 = \frac{1}{2}f_2 - \frac{1}{2}f_3$, so
\[
    P = \begin{pmatrix} 1 & 0 & 0\\
        0 & \frac{1}{2} & \frac{1}{2}\\
        0 & \frac{1}{2} & - \frac{1}{2}
    \end{pmatrix} 
\] 


\textbf{2.6.(1):} Let $s < n$ and $A$ an $s \times n$ matrix
with entries in the field $F$. Use Theorem 4 to show that there is a non-zero
$X$ in $\mathbb{F}^{n \times 1}$ such that $AX = 0$.\\
\textit{Solution:} We have observed that
the product $AX$ is in the row space of $A$ which has dimension at most
$k$. Since $s < n$, we can choose $n$ vectors
$\alpha_1, \ldots, \alpha_n$ and we thus have that
$A \alpha_1, \ldots, A \alpha_n$ are linearly dependent, so there exists
$c_1, \ldots, c_n$ such that
$c_1 A \alpha_1 + \ldots + c_n A \alpha_n
= A \left( c_1 \alpha_1 + \ldots + c_n \alpha_n \right) =0$ where
$c_1 \alpha_1 + \ldots + c_n \alpha_n \neq 0$.\\
\linebreak
\textbf{2.6.(3):} Consider the vectors in $\mathbb{R}^{4}$ defined by
\[
\alpha_1 = \left( -1, 0, 1, 2 \right) , \quad
\alpha_2 = \left( 3,4,-2,5 \right) ,
\quad \alpha_3 = \left( 1,4,0,9 \right) . 
\] 
Find a system of homogeneous linear equations for which the space of solutions
is exactly the subspace of $\mathbb{R}^{4}$ spanned by the three given
vectors.\\
\linebreak
\textit{Solution:} 
$\alpha_2$ is a linear combination of $\alpha_1$ and $\alpha_3$.\\
We try to proceed as on page 59:\\
Let
\[
    A = \begin{pmatrix} 
        1 & 4 & 0 & 9\\
        -1 & 0 & 1 & 2
     \end{pmatrix} 
\] 
which reduces to
\begin{align*}
    \begin{pmatrix} 
        1 & 4 & 0 & 9\\
        -1 & 0 & 1 & 2
     \end{pmatrix} 
     &\to 
     \begin{pmatrix} 1 & 4 & 0 & 9\\
     0 & 4 & 1 & 11 \end{pmatrix} \\
        &\to \begin{pmatrix} 1 & 0 & -1 & -2\\
         0 & 1 & \frac{1}{4} & \frac{11}{4} \end{pmatrix} 
\end{align*}
so
$\left\{ \left( 1,0,-1,-2 \right) ,
\left( 0, 1, \frac{1}{4}, \frac{11}{4} \right) \right\} $
is a basis for the space spanned by $\alpha_1$ and $\alpha_3$.\\
The conditions to be a solution are then
\[
Rb = 0 \iff b_j = \sum_{i=1}^{2} b_{k_i}R_{i,j}, \quad j = 1,\ldots, 4
\] 
So 
$b_1 = b_{k_1} $,
$b_2 = b_{k_2}$,
$b_3 = -1 b_1 + \frac{1}{4} b_2$,
$b_4 = -2 b_1 + \frac{11}{4}b_2$. That is, the subspace is the solution space
for the following system of equations:
\begin{align*}
    x_3 + x_1 - \frac{1}{4} x_2 &= 0\\
    x_4 + 2x_1 - \frac{11}{4}x_2 &= 0
\end{align*}


\textbf{2.6.(5):} Give an explicit description of the type (2-25) for the
vectors
\[
\beta = \left( b_1, b_2, \ldots, b_5 \right) 
\] 
in $\mathbb{R}^{5}$ which are linear combinations of the vectors
\begin{align*}
    \alpha_1 &= \left( 1, 0, 2, 1, -1 \right) \\
    \alpha_2 &= \left( -1,2,-4,2,0 \right) \\
    \alpha_3 &= \left( 2,-1,5,2,1 \right) \\
    a_4 &= \left( 2,1,3,5,2 \right) 
\end{align*}
\textit{Solution:} We find the row-reduced echelon-form matrix of
\begin{align*}
    A = \begin{pmatrix} 1 &0 & 2 & 1 &-1\\
        -1 & 2 & -4 & 2 &0\\
        2 & -1 & 5 & 2 &1\\
        2 & 1 & 3 & 5 & 2
    \end{pmatrix} 
    &\to 
    \begin{pmatrix} 
        1 & 0 & 2 & 1 & -1\\
        0 & 1 & -1 & \frac{3}{2} & 0\\
        0 & -1 & 1 & 0 & 3\\
        0 & 1 & -1 & 3 & 4
    \end{pmatrix} \\
    &\to 
    \begin{pmatrix} 
        1 & 0 & 2 & 1 & -1\\
        0 & 1 & -1 & \frac{3}{2} & 0\\
        0 & 0 & 0 & \frac{3}{2} & 3\\
        0 & 0 & 0 & \frac{3}{2} & 4
    \end{pmatrix} \\
    &\to 
    \begin{pmatrix} 
        1 & 0 & 2 & 1 & -1\\
        0 & 1 & -1 & \frac{3}{2} & 0\\
        0 & 0 & 0 & 1 & 2\\
        0 & 0 & 0 & 0 & 1
    \end{pmatrix}\\
    &\to 
    \begin{pmatrix} 
        1 & 0 & 2 & 0 & 0\\
        0 & 1 & -1 & 0 & 0\\
        0 & 0 & 0 & 1 & 0\\
        0 & 0 & 0 & 0 & 1
    \end{pmatrix} 
\end{align*}
Thus we find
$k_1 = 1, k_2 = 2, k_3 = 4, k_4 = 5$, so
$b_j = \sum_{i=1}^{4} b_{k_i}R_{i j}$ gives
$b_1, b_2$ freely chosen. Then
$b_3 = 2 b_1 - b_2$, and similarly
$b_4$ and $b_5$ freely chosen. So the solutions are of the form\\
$\left( b_1, b_2, 2b_1 - b_2, b_3, b_4 \right) $



\section{Techniques}

\begin{lemma}[]\label{linear-dependence-preceding}
    If $V$ is a vector space, and $\left( v_1, \ldots,
    v_k \right) $ is a linearly dependent $k$-tuple in $V$ with
    $v_1 \neq 0$, then some $v_i$ can be expressed as a linear combination of
    the \textit{preceding} vectors
    $\left( v_1, \ldots, v_{i-1} \right) $.
\end{lemma}

\begin{lemma}[]
    Let $V$ be a finite-dim vec. space and
    $S \subset V$ a subspace in $V$. Then given an arbitrary basis
    $\left( \alpha_1, \ldots, \alpha_n \right) $ for $V$, there exists some
    subset $\left\{ i_1, \ldots, i_k \right\} \subset 
    \left\{ 1, \ldots, n \right\} $ such that
    $\Span \left( \alpha_{i_1}, \ldots,
    \alpha_{i_k} \right) $ is a complement to $S$.
\end{lemma}

\begin{proof}
    Use Lemma \ref{linear-dependence-preceding}.
\end{proof}










\end{document}
